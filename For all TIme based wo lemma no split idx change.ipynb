{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from empath import Empath\n",
    "lexicon = Empath()\n",
    "from stanza.server import CoreNLPClient\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lexicon.create_category(\"custom_times\", [\"once_upon_a_time\", \"next_day\",\"that_evening\"], size = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lexicon.create_category(\"custom_times_3\", [\"when\", \"next_day\",\"one_time\"], size = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"sundown\", \"midday\", \"next_day\", \"ten_o'clock\", \"noon\", \"Sunday_night\", \"3pm\", \"mid-day\", \"eight_o'clock\", \"mid_day\", \"seven_o'clock\", \"10pm\", \"about_noon\", \"midday\", \"8_o'clock\", \"6_pm\", \"eleven\", \"early_morning\", \"nine_o'clock\", \"5pm\", \"4pm\", \"5:00_pm\", \"five_o'clock\", \"midnight\", \"earliest\", \"six_o'clock\", \"6pm\", \"9pm\", \"four_o'clock\", \"nightfall\", \"Thursday_night\", \"8pm\", \"Monday_night\", \"late_afternoon\", \"around_eight\", \"4:00\", \"next_night\", \"ten_thirty\", \"noon\", \"11_o'clock\", \"10_o'clock\", \"7pm\", \"Sunday_morning\", \"daybreak\", \"dusk\", \"9_o'clock\", \"around_noon\", \"7:00_pm\", \"night_fall\", \"final_day\", \"5_o'clock\", \"Saturday_afternoon\", \"5_p.m.\", \"Sunday_night\", \"six_thirty\", \"nine_o'clock\", \"three_o'clock\", \"following_day\", \"nine\", \"11:30\", \"the_day_after\", \"Wednesday_night\", \"tomorrow_morning\", \"tomorrow_morning\", \"11pm\", \"4_o'clock\", \"around_three\", \"10am\", \"two_more_days\", \"9am\", \"late_evening\", \"8am\", \"6:00_pm\", \"12:00\", \"following\", \"the_third_day\", \"normal_time\", \"8_pm\", \"10am\", \"eleven_o'clock\", \"eight_thirty\", \"10_pm\", \"10:00\", \"6_o'clock\", \"7_o'clock\", \"9_pm\", \"Tomorrow\", \"reasonable_time\", \"12:00_pm\", \"four_thirty\", \"afternoon\", \"3:30\", \"11_pm\", \"eight_days\", \"next_full_moon\", \"seven_thirty\", \"Tuesday_night\", \"late_night\", \"5pm\", \"3:30\", \"3:00\", \"the_morning\", \"Sunday\", \"4_pm\", \"9_am\", \"3:00\", \"3pm\", \"the_next_days\", \"9:00_pm\", \"about_midnight\", \"evening\", \"5:00\", \"one_hour\", \"dinnertime\", \"Christmas_Eve\", \"New_Year's_Eve\", \"eight\", \"1_a.m.\", \"eleven_thirty\", \"10:00\", \"following_morning\", \"9:00\", \"forty-five_minutes\", \"time_school\", \"the_following_day\", \"the_day_after_tomorrow\", \"10_a.m.\", \"only_a_few_hours\", \"work_day\", \"Sunday_afternoon\", \"five_thirty\", \"1:30\", \"9:30\", \"12:00\", \"the_New_Year\", \"1pm\", \"a_few_hours\", \"5:00\", \"Sometime\", \"7_pm\", \"2:00\", \"4:00\", \"10pm\", \"2:00\", \"10:30\", \"4:00_pm\", \"10_pm\", \"five_in_the_morning\", \"the_fourth_day\", \"seven_in_the_morning\", \"late_afternoon\", \"sunday\", \"next_Monday\", \"next_Saturday\", \"nighttime\", \"only_two_days\", \"school_time\", \"eight_hours\", \"late_morning\", \"three_more_days\", \"Saturday\", \"8:00_pm\", \"Christmas_Eve\", \"school_starts\", \"8_a.m.\", \"11:00\", \"11:00_pm\", \"12:30\", \"certain_time\", \"10_am\", \"festival\", \"til\", \"first_light\", \"9_a.m.\", \"tomorrow_afternoon\", \"Tuesday_morning\", \"9:00pm\", \"4:30\", \"Thursday\", \"about_5_hours\", \"rest_day\", \"1:00\", \"dinner_time\", \"Christmas_eve\", \"long_weekend\", \"8:00_am\", \"late_at_night\", \"the_end_of_the_summer\", \"6:00\", \"9:00\", \"five-thirty\", \"the_big_day\", \"late_that_night\", \"camping_trip\", \"Friday_afternoon\", \"nine-thirty\", \"next_Thursday\", \"Saturday_morning\", \"Spring_Break\", \"the_fifth_day\", \"Winter_Break\", \"4:30\", \"9:30\", \"5_pm\", \"2pm\", \"2:30\", \"dawn\", \"4:00\", \"Christmas_vacation\", \"New_Year's\", \"six_hours\", \"forty_five_minutes\", \"Friday_morning\", \"8:30\", \"only_an_hour\", \"10:00_pm\", \"Wednesday\", \"weekday\", \"Christmas_break\", \"Spring_break\", \"Saturday\", \"nights\", \"next_shift\", \"3:30\", \"busiest\", \"winter_solstice\", \"rendezvous\", \"Tommorow\", \"the_next_day\", \"usual_time\", \"10:00\", \"sunrise\", \"closing_time\", \"New_Year\\u2019s_Eve\", \"6:00\", \"next_Sunday\", \"9:00am\", \"7.30\", \"New_Years\", \"new_moon\", \"training_session\", \"next_morning\", \"ten_days\", \"another_few_hours\", \"3:00_pm\", \"afternoon\", \"cheer_practice\", \"12:00_am\", \"2:00\", \"about_four_hours\", \"6:00pm\", \"solstice\", \"1:30\", \"12pm\", \"Reaping\", \"3_o'clock\", \"Wednesday_morning\", \"6:30\", \"night_time\", \"1:00\", \"til\", \"11:30\", \"morrow\", \"summer_holiday\", \"supper_time\", \"Tomorrow\", \"9:00\", \"6am\", \"the_next_two_days\", \"this_Sunday\", \"six_days\", \"5:30\", \"training_camp\", \"the_next_month\", \"5:30\", \"last_Friday\", \"12:00\", \"two_days_time\", \"2_more_days\", \"only_day\", \"4:30\", \"12:30\", \"luncheon\", \"8_p.m.\", \"Christmas_holidays\", \"tomorrow_evening\", \"10:30\", \"another_three_hours\", \"6_am\", \"about_six_hours\", \"a_half_day\", \"11:00\", \"later_tonight\", \"2:00_pm\", \"another_half_hour\", \"less_than_an_hour\", \"tomorrow\", \"tommorow\", \"next_week\", \"summer_holidays\", \"tomorrow\", \"ten\", \"5am\", \"afterschool\", \"Five_hours\", \"11:00\", \"about_one_hour\", \"Tuesday\", \"sunday\", \"pack_meeting\", \"three_in_the_afternoon\", \"2:00_am\", \"8:00\", \"the_month\", \"8:45\", \"Halloween\", \"the_new_year\", \"Friday\", \"about_4_hours\", \"tomorrow_night\", \"2:30\", \"big_night\", \"a_busy_day\", \"8:00pm\", \"Christmas\", \"exact_time\", \"a_big_day\", \"our_day\", \"monday\", \"next_Friday\", \"that_hour\", \"six_in_the_morning\", \"youth_group\", \"couple_hours\", \"almost_midnight\", \"6pm\", \"30_minutes\", \"Summer_break\", \"only_an_hour\", \"seven_hours\", \"New_Years_Eve\", \"2_hours\", \"Thanksgiving_break\", \"5:30_pm\", \"nine_in_the_morning\", \"11:00_am\", \"Sunday\", \"1pm\", \"camp\", \"night\", \"Curfew\", \"decent_time\", \"12:30\", \"regular_day\", \"saturday\", \"dusk\", \"full_day\", \"four_hours\", \"the_day\", \"big_meeting\", \"Friday\", \"third_day\", \"3:00\", \"postponed\", \"six_thirty\", \"midnight\", \"another_week\", \"8_am\", \"Graduation\", \"Thursday_morning\", \"the_next_couple_of_weeks\", \"Gathering\", \"early_morning\", \"early_start\", \"next_Wednesday\", \"tommorrow\", \"evening\", \"the_wee_hours_of_the_morning\", \"Christmas_time\", \"next_summer\", \"last_Sunday\", \"reaping\", \"football_season\", \"school_week\", \"8:00\", \"dreadful_day\", \"7:00\", \"5.30\", \"Easter\", \"a_weekend\", \"6am\", \"reaping\", \"6:30\", \"11:30_pm\", \"1am\", \"7:00\", \"Thanksgiving\", \"1:00_pm\", \"graduation_ceremony\", \"tuesday\", \"2:30\", \"lunchtime\", \"less_than_an_hour\", \"scheduled\", \"7:00pm\", \"Graduation\", \"early_hours\", \"cookout\", \"main_event\", \"Christmas_Eve\", \"6_a.m.\", \"6:00\", \"seven_days\", \"morn\", \"tutoring_session\", \"date_night\", \"council_meeting\", \"New_Years\", \"Monday_morning\", \"5:00\", \"8:00\", \"3:00_am\", \"winter_break\", \"Port_Angeles\", \"twenty_five_minutes\", \"the_end_of_summer\", \"12:00\", \"7:45\", \"school_days\", \"forty_minutes\", \"September_1st\", \"about_11\", \"Thanksgiving\", \"A.M.\", \"only_three_days\", \"another_month\", \"Monday\", \"2pm\", \"the_next_week\", \"only_two_hours\", \"7:30_pm\", \"wednesday\", \"8:00am\", \"school_ends\", \"long_trip\", \"underway\", \"3_a.m.\", \"1:30\", \"10:30_pm\", \"Saturday_night\", \"five_weeks\", \"8:15\", \"specific_time\", \"just_a_few_hours\", \"1:00\", \"ten_minutes\", \"purge\", \"6:30_pm\", \"many_days\", \"Friday_evening\", \"Early\", \"9_days\", \"last_week\", \"good_nights_sleep\", \"an_hour_and_a_half\", \"7:30\", \"One_week\", \"P.M.\", \"thanksgiving\", \"dance_practice\", \"6:30pm\", \"8:30\", \"6:00pm\", \"7:30\", \"nine_thirty\", \"two_weeks_time\", \"tomarrow\", \"10:30\", \"morning_shift\", \"10_days\", \"6_hours\", \"only_three_hours\", \"December\", \"7:00am\", \"second_day\", \"eight_in_the_morning\", \"only_2_days\", \"5:00\", \"Christmas_party\", \"11am\", \"only_twenty_minutes\", \"eleven_at_night\", \"13_minutes\", \"their_day\", \"twenty_minutes\", \"Spring_Break\", \"thursday\", \"a_day\", \"Prom\", \"retire\", \"boat_ride\", \"coronation\", \"just_a_normal_day\", \"7am\", \"only_2_hours\", \"the_end_of_our\", \"next_Tuesday\", \"another_day\", \"each_morning\", \"9:30\", \"September\", \"few_hours\", \"five_hours\", \"sixteenth\", \"Hyde_Park\", \"A_day\", \"7_a.m.\", \"only_20_minutes\", \"free_day\", \"dinner_party\", \"the_third_week\", \"March\", \"Sundays\", \"grand_opening\", \"march\", \"til\", \"9_hours\", \"spring_break\", \"late_tonight\", \"the_last_days\", \"weeks_time\", \"6:30am\", \"friday\", \"about_five_hours\", \"4_in_the_morning\", \"about_a_half_hour\", \"8_days\", \"each_night\", \"morning_walk\", \"New_Year\", \"a_few_hours_before\", \"September\", \"almost_time\", \"6_am\", \"five\", \"12_hours\", \"Every_day\", \"the_next_three_weeks\", \"choosing_ceremony\", \"two_nights\", \"most_nights\", \"four_in_the_morning\", \"about_the_time\", \"the_next_three_days\", \"5_am\", \"5:45\", \"Christmas_Break\", \"early\", \"Tomorrow_night\", \"rush_hour\", \"art_show\", \"lunch_hour\", \"busy_day\", \"2:45\", \"7:00\", \"only_five_minutes\", \"fieldtrip\", \"big_game\", \"One_month\", \"half_a_day\", \"10_am\", \"volleyball_practice\", \"five_minutes\", \"another_2_hours\", \"about_3\", \"one_week\", \"this_Friday\", \"5:30_in_the_morning\", \"Supper\", \"Remembering\", \"summer_break\", \"nine_hours\", \"arriving\", \"field_trip\", \"all_week\", \"charity_event\", \"night\", \"the_next_two_weeks\", \"four_minutes\", \"January_1st\", \"one_morning\", \"daytime\", \"three_day\", \"9_in_the_morning\", \"the_end_of_the\", \"retiring\", \"18th\", \"summer_vacation\", \"about_2_days\", \"three_weeks_later\", \"long_car_ride\", \"Training\", \"6:00_am\", \"we\\u2019d\", \"12:30\", \"another_two_days\", \"five_days\", \"2:15\", \"still\", \"6.30\", \"6:45\", \"first_practice\", \"family_day\", \"9:45\", \"job_hunting\", \"7_hours\", \"15th\", \"friday\", \"second_task\", \"eight_minutes\", \"daylight_hours\", \"preparations\", \"7_days\", \"christmas\", \"day_time\", \"10:30_am\", \"10_in_the_morning\", \"fourteenth\", \"Two_weeks\", \"dinner_reservations\", \"13th\", \"saturday\", \"2_hours\", \"pm\", \"February\", \"7:40\", \"Every_morning\", \"thanksgiving\", \"four_days\", \"10:45\", \"boring_day\", \"resort\", \"premiere\", \"Camp\", \"very_important_day\", \"later_tonight\", \"long_journey\", \"deadline\", \"Saturday_night\", \"curfew\", \"til\", \"6:30\", \"prepare\", \"7:45\", \"next_town\", \"11:30\", \"nigh\", \"5_days\", \"very_long_day\", \"4:45\", \"Tonight\", \"band_camp\", \"7_am\", \"home\", \"35_minutes\", \"train_ride\", \"at_least_two_hours\", \"Tryouts\", \"Saturdays\", \"twelve_hours\", \"eighteenth\", \"the_following_week\", \"every_year\", \"first_session\", \"the_first_week\", \"untill\", \"second_week\", \"3:00pm\", \"8:30\", \"opening_ceremony\", \"day\", \"morning-\", \"4_am\", \"excursion\", \"Rehearsals\", \"5:30\", \"eleven\", \"4:00_am\", \"Universal_Studios\", \"morning\", \"first_month\", \"Monday_afternoon\", \"Homecoming\", \"new_day\", \"nighttime\", \"3:15\", \"8:00_a.m.\", \"Finals\", \"last_day\", \"November\", \"family_dinner\", \"October\", \"Todays\", \"half_an_hour_ago\", \"brunch\", \"10:00\", \"tea_time\", \"soccer_practice\", \"next_city\", \"o\\u2019clock\", \"new_years\", \"thirty_minutes\", \"10:00_am\", \"11:30\", \"three_in_the_morning\", \"same_routine\", \"Monday\", \"long_hours\", \"3am\", \"filming\", \"orientation\", \"late_hours\", \"26th\", \"the_early_hours_of_the_morning\", \"tomorrows\", \"just_a_day\", \"10_at_night\", \"about_three_hours\", \"morning\", \"more_hour\", \"day_trip\", \"the_next_two_months\", \"Noon\", \"14_days\", \"the_school_year\", \"another_night\", \"5:30\", \"radio_interview\", \"ten_hours\", \"the_whole_day\", \"8:30pm\", \"this_afternoon\", \"a_half_hour\", \"theme_park\", \"school_night\", \"8:30_pm\", \"good_night's_rest\", \"4am\", \"only_a_week\", \"new_year\", \"expedition\", \"12:15\", \"three_days_later\", \"just_another_day\", \"weekdays\", \"two_week\", \"the_spring\", \"monday\", \"final_test\", \"three_more_hours\", \"Christmas_shopping\", \"the_next_few_days\"]\n"
     ]
    }
   ],
   "source": [
    "lexicon.create_category(\"custom_times_2\",\n",
    "                        [\"next_day\",\"nex_month\",\"next_year\",\"one_day\",\"once_upon_a_time\",\"that_evening\",\"sundown\",\"later_that_day\",\n",
    "                         \"two_hours_later\"],\n",
    "                        size =1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Lemmatization of this is heavily required\n",
    "# lexicon.create_category(\"religious_buildings\", [\"church\",\"mosque\", \"temple\"], model=\"fiction\", size = 30)\n",
    "# lexicon.create_category(\"loc_verbs\", [\"arrive\", \"visit\", \"travel\", \"return\"], model = \"fiction\", size= 14)\n",
    "# lexicon.create_category(\"fictional_places\", [\"place\",\"buildings\"], model =\"fiction\", size =300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the_story_of_the_merchant_son', 'the_thief_and_the_brahmins', 'the_monkey_the_wedge', 'a_daring_plan', 'Buddha_remains_cool', 'moocha_raja', 'raman_horse_trainer', 'talkative_turtle', 'tenali_outwits_guards', 'tenali_the_detective', 'the_three_promises', 'the_weaver_and_the_princess']\n"
     ]
    }
   ],
   "source": [
    "story_names = []\n",
    "file = open(\"D:\\Jupyter\\BTP\\Panchatantra\\Storynames_new.txt\")\n",
    "file_story_names = file.readlines()\n",
    "for name in file_story_names:\n",
    "    story_names.append(name.strip('\\n'))\n",
    "file.close()\n",
    "print(story_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the_story_of_the_merchant_son', 'the_thief_and_the_brahmins', 'the_monkey_and_the_crocodile', 'the_monkey_the_wedge', 'a_daring_plan', 'Buddha_remains_cool', 'moocha_raja', 'raman_horse_trainer', 'talkative_turtle', 'tenali_outwits_guards', 'tenali_the_detective']\n"
     ]
    }
   ],
   "source": [
    "story_names = []\n",
    "file = open(\"D:\\Jupyter\\BTP\\Panchatantra\\Storynames_new.txt\")\n",
    "file_story_names = file.readlines()\n",
    "for name in file_story_names:\n",
    "    story_names.append(name.strip('\\n'))\n",
    "file.close()\n",
    "print(story_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_sentence(sentence):\n",
    "    #tokenize the sentence and find the POS tag for each token\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    #tuple of (token, wordnet_tag)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged)\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            #if there is no available tag, append the token as is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:        \n",
    "            #else use the tag to lemmatize the token\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_story(Storyname):\n",
    "    file = open(\"D:\\Jupyter\\BTP\\Panchatantra\\\\\"+Storyname+'.txt', encoding = 'utf-8')\n",
    "    text = file.read()\n",
    "    text = unidecode(text)\n",
    "    file.close()\n",
    "    return text\n",
    "def annotate_story(text):\n",
    "    with CoreNLPClient(annotators = ['tokenize','ssplit'],\n",
    "        memory='5G', be_quiet=True, outputFormat = 'json', max_char_length=500000, timeout=36000000) as client:\n",
    "        annotated_story = client.annotate(text)\n",
    "    return annotated_story\n",
    "def open_and_annotate(Storyname):\n",
    "    text = open_story(Storyname)\n",
    "    annotated_story = annotate_story(text)\n",
    "    return text, annotated_story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_splitting = [[4, 14, 15, 16, 21, 22, 30, 46, 47, 52, 53],\n",
    "                [15, 16, 19, 20, 25, 26, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 45, 46],\n",
    "                [4, 5, 16, 17, 20, 26, 27, 28, 29, 39, 40, 44, 45, 46, 47, 53, 54, 55, 56, 57],\n",
    "                [],\n",
    "                [6, 15, 16, 26, 27, 28],\n",
    "                [11, 17, 18, 19, 20, 21, 22],\n",
    "                [],\n",
    "                [],\n",
    "                [10, 11, 12, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 39],\n",
    "                [14, 15, 16, 17, 18, 30, 31, 32, 33, 34],\n",
    "                [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 24, 25, 34, 35, 36, 37, 38],\n",
    "               ]\n",
    "\n",
    "no_splitting_alternate = [[4, 5, 14, 15, 16, 17, 21, 22, 23, 30, 31, 46, 47, 48, 52, 53, 54],\n",
    "[15, 16, 17, 19, 20, 21, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 45, 46, 47],\n",
    "[4, 5, 6, 16, 17, 18, 20, 21, 26, 27, 28, 29, 30, 39, 40, 41, 44, 45, 46, 47, 48, 53, 54, 55, 56, 57, 58],\n",
    "[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def events_by_time(text,ann):\n",
    "    \"\"\"\n",
    "    Non-hierarchy model\n",
    "    \"\"\"\n",
    "    #This function finds sum of dictionary returned by lexicon.analyze i.e., it finds the presence of location words.\n",
    "    def sum_of_locs_dict(dictionary):\n",
    "        sum_ = 0\n",
    "        for key in dictionary.keys():\n",
    "            sum_ = sum_ + dictionary[key]\n",
    "        return sum_\n",
    "       \n",
    "    lexicon = Empath()   #Part of code used to bring Empath in\n",
    "    locations_dict = dict()     #Dictionary that holds\n",
    "    location = \"Unknown\"    #The variable place will hold latest location word.\n",
    "                            #It is initilized to \"unknown\" beacuse till now we haven't encountered any location word.\n",
    "    loaction_by_sentence = []\n",
    "    location_to_number = dict() # Convert location words to numbers for better representation\n",
    "    loc_num = 0 # Will be used to put location words as numbers in the location_to_number dict\n",
    "    total_sentences = 0\n",
    "    \n",
    "    #Take each sentence of the story one by one (ann.sentence returns individual sentences of the story as objects)\n",
    "    for i, sentence in enumerate(ann.sentence):\n",
    "        # Remove comma and fullstop beacuse lexicon.analyze cannot identify words if they are followd by a fullstop or comma.\n",
    "        # text[characterOffsetBegin:characterOffserEnd] is the actual sentence (as a string) of the sentence object returned\n",
    "        sentence_for_empath = text[sentence.characterOffsetBegin:sentence.characterOffsetEnd].replace(\", \",\" \").replace(\".\",\"\").replace(\"-\",\" \").replace(\"?\",\"\").replace(\"!\",\"\").replace(\":\",\" \")\n",
    "        #Lemmatize the words you encounter for better identification when being analysed by lexicon.analyze\n",
    "        #May be commented out because lexicon.create_category does not give good words when singular words are used\n",
    "        sentence_for_empath = lemmatize_sentence(sentence_for_empath) # Sentences are all lemmatized now\n",
    "        # Analyze the things\n",
    "        lexicon_locations_dict = lexicon.analyze(sentence_for_empath, categories = [\"custom_times_2\"])\n",
    "                                                \n",
    "        s = sum_of_locs_dict(lexicon_locations_dict)\n",
    "        if s>0:\n",
    "            words = sentence_for_empath.split(\" \")\n",
    "            # Find if place is same as previous\n",
    "            for word in words:\n",
    "                # If the word is a location word\n",
    "                if sum_of_locs_dict(lexicon.analyze(word, categories = ['custom_times_2']))>0:                                                 \n",
    "                    #if new location word encountered is the same as the last location word encountered\n",
    "                    if word == location:\n",
    "                        break\n",
    "                    else:\n",
    "                        location = word\n",
    "                        if location in locations_dict:\n",
    "                            location+=\"1\"\n",
    "                        locations_dict[location]=[i-1]\n",
    "                        location_to_number[location] = loc_num\n",
    "                        loc_num += 1\n",
    "        else: \n",
    "            if location not in locations_dict:\n",
    "                locations_dict[location] = list()\n",
    "            locations_dict[location].append(i-1)\n",
    "        total_sentences = i\n",
    "    return locations_dict, location_to_number, total_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_event_list(locations_dict, no_split):  #Extra parameter no_split added. Parameter take no_splitting[i] for ith story\n",
    "    events= []\n",
    "    for location in locations_dict:\n",
    "        if locations_dict[location][0] not in no_split:\n",
    "            events.append(locations_dict[location][0])\n",
    "    events.sort()\n",
    "    events.append(total_sentences)\n",
    "    while events[0] == -1:\n",
    "        del events[0]\n",
    "    return set(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-18 17:26:05 INFO: Writing properties to tmp file: corenlp_server-5d48d318608c4c34.props\n",
      "2021-04-18 17:26:05 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-5d48d318608c4c34.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-04-18 17:26:07 INFO: Writing properties to tmp file: corenlp_server-a1ec38f1a82b4687.props\n",
      "2021-04-18 17:26:07 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-a1ec38f1a82b4687.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-04-18 17:26:09 INFO: Writing properties to tmp file: corenlp_server-1c192b4d8f2144c2.props\n",
      "2021-04-18 17:26:09 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-1c192b4d8f2144c2.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-04-18 17:26:11 INFO: Writing properties to tmp file: corenlp_server-fb9d1bd0fc7f48f5.props\n",
      "2021-04-18 17:26:11 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-fb9d1bd0fc7f48f5.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-04-18 17:26:12 INFO: Writing properties to tmp file: corenlp_server-cac5421d03ff4478.props\n",
      "2021-04-18 17:26:12 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-cac5421d03ff4478.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-04-18 17:26:14 INFO: Writing properties to tmp file: corenlp_server-03a84817e9614923.props\n",
      "2021-04-18 17:26:14 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-03a84817e9614923.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-04-18 17:26:15 INFO: Writing properties to tmp file: corenlp_server-4bb966ff6cd44147.props\n",
      "2021-04-18 17:26:15 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-4bb966ff6cd44147.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-04-18 17:26:17 INFO: Writing properties to tmp file: corenlp_server-bd71496fa6534504.props\n",
      "2021-04-18 17:26:17 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-bd71496fa6534504.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-04-18 17:26:18 INFO: Writing properties to tmp file: corenlp_server-2f61a509989e4732.props\n",
      "2021-04-18 17:26:18 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-2f61a509989e4732.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-04-18 17:26:20 INFO: Writing properties to tmp file: corenlp_server-a5742819a97d4a68.props\n",
      "2021-04-18 17:26:20 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-a5742819a97d4a68.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-04-18 17:26:21 INFO: Writing properties to tmp file: corenlp_server-e8c6650928164078.props\n",
      "2021-04-18 17:26:21 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-e8c6650928164078.props -annotators tokenize,ssplit -preload -outputFormat serialized\n"
     ]
    }
   ],
   "source": [
    "my_list_of_events = []\n",
    "for i,name in enumerate(story_names):\n",
    "    text , annotated_story = open_and_annotate(name)\n",
    "    locations_dict, location_number_map, total_sentences = events_by_time(text, annotated_story)\n",
    "    my_list_of_events.append(construct_event_list(locations_dict,no_splitting[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0, 18, 27, 40, 57, 65},\n",
       " {1, 17, 21, 48},\n",
       " {0, 11},\n",
       " {8, 33},\n",
       " {32},\n",
       " {37},\n",
       " {5, 22},\n",
       " {0, 25, 52, 56},\n",
       " {37},\n",
       " {38},\n",
       " {51},\n",
       " {36, 58, 63}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list_of_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0, 18, 27, 40, 57, 65},\n",
       " {1, 17, 21, 48},\n",
       " {0, 1, 8, 32, 60},\n",
       " {0, 11},\n",
       " {8, 33},\n",
       " {32},\n",
       " {22, 37},\n",
       " {5, 22},\n",
       " {0, 25, 52, 56},\n",
       " {37},\n",
       " {31, 38}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list_of_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 18, 27, 40, 57, 65], [1, 17, 21, 48], [0, 11], [8, 33], [32], [37], [5, 22], [0, 25, 52, 56], [37], [38], [51], [36, 58, 63]]\n"
     ]
    }
   ],
   "source": [
    "my_list_of_events_2 = []\n",
    "for i,event in enumerate(my_list_of_events):    \n",
    "    x = sorted(list(event))\n",
    "    my_list_of_events_2.append(x)\n",
    "print(my_list_of_events_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 18, 27, 40, 57, 65], [1, 17, 21, 48], [0, 1, 8, 32, 60], [0, 11], [8, 33], [32], [22, 37], [5, 22], [0, 25, 52, 56], [37], [31, 38]]\n"
     ]
    }
   ],
   "source": [
    "my_list_of_events_2 = []\n",
    "for i,event in enumerate(my_list_of_events):    \n",
    "    x = sorted(list(event))\n",
    "    my_list_of_events_2.append(x)\n",
    "print(my_list_of_events_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
