{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from empath import Empath\n",
    "import requests\n",
    "import json\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_category(self,name,seeds,model=\"fiction\",size=100,write=True):\n",
    "    resp = requests.post(self.backend_url + \"/create_category\", json={\"terms\":seeds,\"size\":size,\"model\":model})\n",
    "    results = json.loads(resp.text)\n",
    "    lemma_words = list()\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    for word in results:\n",
    "        lemma_words.append(lemmatizer.lemmatize(word))\n",
    "    self.cats[name] = list(set(lemma_words))\n",
    "    if write:\n",
    "        with open(self.base_dir+\"/data/user/\"+name+\".empath\",\"w\") as f:\n",
    "            f.write(\"\\t\".join([name]+results))\n",
    "\n",
    "Empath.create_lemma_category = create_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "lexicon = Empath()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from stanza.server import CoreNLPClient\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lexicons(rb,lv,fp,ct):\n",
    "    lexicon.create_lemma_category(\"religious_buildings\", [\"church\",\"mosque\", \"temple\"], model=\"fiction\", size = rb)\n",
    "    lexicon.create_lemma_category(\"loc_verbs\", [\"arrive\", \"visit\", \"travel\", \"return\"], model = \"fiction\", size= lv)\n",
    "    lexicon.create_lemma_category(\"fictional_places\", [\"place\",\"buildings\"], model =\"fiction\", size =fp)\n",
    "    lexicon.create_lemma_category(\"custom_times\", [\"once_upon_a_time\", \"next_day\",\"that_evening\"], size = ct)\n",
    "    #lexicon.create_lemma_category(\"custom_times\", [\"next_day\",\"nex_month\",\"next_year\",\"one_day\",\"once_upon_a_time\",\n",
    "    #                                               \"that_evening\",\"sundown\",\"later_that_day\",\"two_hours_later\"], size = ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_lexicons(30,14,300,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_sentence(sentence):\n",
    "    #tokenize the sentence and find the POS tag for each token\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    #tuple of (token, wordnet_tag)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged)\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            #if there is no available tag, append the token as is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:        \n",
    "            #else use the tag to lemmatize the token\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the_story_of_the_merchant_son', 'the_thief_and_the_brahmins', 'the_monkey_and_the_crocodile', 'the_monkey_the_wedge', 'a_daring_plan', 'Buddha_remains_cool', 'moocha_raja', 'raman_horse_trainer', 'talkative_turtle', 'tenali_outwits_guards', 'tenali_the_detective']\n"
     ]
    }
   ],
   "source": [
    "story_names = []\n",
    "file = open(\"D:\\Jupyter\\BTP\\Panchatantra\\Storynames_new.txt\")\n",
    "file_story_names = file.readlines()\n",
    "for name in file_story_names:\n",
    "    story_names.append(name.strip('\\n'))\n",
    "file.close()\n",
    "print(story_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the_story_of_the_merchant_son', 'the_thief_and_the_brahmins', 'the_monkey_and_the_crocodile', 'the_monkey_the_wedge', 'a_daring_plan', 'Buddha_remains_cool', 'moocha_raja', 'raman_horse_trainer', 'talkative_turtle', 'tenali_outwits_guards', 'tenali_the_detective']\n"
     ]
    }
   ],
   "source": [
    "story_names = []\n",
    "file = open(\"D:\\Jupyter\\BTP\\Panchatantra\\Storynames_new.txt\")\n",
    "file_story_names = file.readlines()\n",
    "for name in file_story_names:\n",
    "    story_names.append(name.strip('\\n'))\n",
    "file.close()\n",
    "print(story_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_splitting = [[4, 14, 15, 16, 21, 22, 30, 46, 47, 52, 53],\n",
    "                [15, 16, 19, 20, 25, 26, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 45, 46],\n",
    "                [4, 5, 16, 17, 20, 26, 27, 28, 29, 39, 40, 44, 45, 46, 47, 53, 54, 55, 56, 57],\n",
    "                [],\n",
    "                [6, 15, 16, 26, 27, 28],\n",
    "                [11, 17, 18, 19, 20, 21, 22],\n",
    "                [],\n",
    "                [],\n",
    "                [10, 11, 12, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 39],\n",
    "                [14, 15, 16, 17, 18, 30, 31, 32, 33, 34],\n",
    "                [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 24, 25, 34, 35, 36, 37, 38],\n",
    "               ]\n",
    "\n",
    "no_splitting_alternate = [[4, 5, 14, 15, 16, 17, 21, 22, 23, 30, 31, 46, 47, 48, 52, 53, 54],\n",
    "[15, 16, 17, 19, 20, 21, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 45, 46, 47],\n",
    "[4, 5, 6, 16, 17, 18, 20, 21, 26, 27, 28, 29, 30, 39, 40, 41, 44, 45, 46, 47, 48, 53, 54, 55, 56, 57, 58],\n",
    "[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_story(Storyname):\n",
    "    file = open(\"D:\\Jupyter\\BTP\\Panchatantra\\\\\"+Storyname+'.txt', encoding = 'utf-8')\n",
    "    text = file.read()\n",
    "    text = unidecode(text)\n",
    "    file.close()\n",
    "    return text\n",
    "def annotate_story(text):\n",
    "    with CoreNLPClient(annotators = ['tokenize','ssplit'],\n",
    "        memory='5G', be_quiet=True, outputFormat = 'json', max_char_length=500000, timeout=36000000) as client:\n",
    "        annotated_story = client.annotate(text)\n",
    "    return annotated_story\n",
    "def open_and_annotate(Storyname):\n",
    "    text = open_story(Storyname)\n",
    "    annotated_story = annotate_story(text)\n",
    "    return text, annotated_story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def events_by_location_and_time(text,ann):\n",
    "    \"\"\"\n",
    "    Non-hierarchy model\n",
    "    \"\"\"\n",
    "    #This function finds sum of dictionary returned by lexicon.analyze i.e., it finds the presence of location words.\n",
    "    def sum_of_locs_dict(dictionary):\n",
    "        sum_ = 0\n",
    "        for key in dictionary.keys():\n",
    "            sum_ = sum_ + dictionary[key]\n",
    "        return sum_\n",
    "       \n",
    "    lexicon = Empath()   #Part of code used to bring Empath in\n",
    "    locations_dict = dict()     #Dictionary that holds\n",
    "    location = \"Unknown\"    #The variable place will hold latest location word.\n",
    "                            #It is initilized to \"unknown\" beacuse till now we haven't encountered any location word.\n",
    "    loaction_by_sentence = []\n",
    "    location_to_number = dict() # Convert location words to numbers for better representation\n",
    "    loc_num = 0 # Will be used to put location words as numbers in the location_to_number dict\n",
    "    total_sentences = 0\n",
    "    \n",
    "    #Take each sentence of the story one by one (ann.sentence returns individual sentences of the story as objects)\n",
    "    for i, sentence in enumerate(ann.sentence):\n",
    "        # Remove comma and fullstop beacuse lexicon.analyze cannot identify words if they are followd by a fullstop or comma.\n",
    "        # text[characterOffsetBegin:characterOffserEnd] is the actual sentence (as a string) of the sentence object returned\n",
    "        sentence_for_empath = text[sentence.characterOffsetBegin:sentence.characterOffsetEnd].replace(\", \",\" \").replace(\".\",\"\").replace(\"-\",\" \").replace(\"?\",\"\").replace(\"!\",\"\").replace(\":\",\" \")\n",
    "        #Lemmatize the words you encounter for better identification when being analysed by lexicon.analyze\n",
    "        #May be commented out because lexicon.create_category does not give good words when singular words are used\n",
    "        sentence_for_empath = lemmatize_sentence(sentence_for_empath) # Sentences are all lemmatized now\n",
    "        # Analyze the things\n",
    "        lexicon_locations_dict = lexicon.analyze(sentence_for_empath,\n",
    "                                                categories=[\"religious_buildings\", \"loc_verbs\", \"fictional_places\", \"custom_times\"])\n",
    "        \n",
    "        s = sum_of_locs_dict(lexicon_locations_dict)\n",
    "        if s>0:\n",
    "            words = sentence_for_empath.split(\" \")\n",
    "            # Find if place is same as previous\n",
    "            for word in words:\n",
    "                # If the word is a location word\n",
    "                if sum_of_locs_dict(lexicon.analyze(word,\n",
    "                                                   categories=[\"religious_buildings\", \"loc_verbs\", \"fictional_places\", \"custom_times\"]))>0:\n",
    "                    #if new location word encountered is the same as the last location word encountered\n",
    "                    if word == location:\n",
    "                        break\n",
    "                    else:\n",
    "                        location = word\n",
    "                        if location in locations_dict:\n",
    "                            location+=\"1\"\n",
    "                        locations_dict[location]=[i-1]\n",
    "                        location_to_number[location] = loc_num\n",
    "                        loc_num += 1\n",
    "        else: \n",
    "            if location not in locations_dict:\n",
    "                locations_dict[location] = list()\n",
    "            locations_dict[location].append(i-1)\n",
    "        total_sentences = i\n",
    "    return locations_dict, location_to_number, total_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_event_list(locations_dict, no_split):\n",
    "    events= []\n",
    "    for location in locations_dict:\n",
    "        if locations_dict[location][0] not in no_split:\n",
    "            events.append(locations_dict[location][0])\n",
    "    events.sort()\n",
    "    events.append(total_sentences)\n",
    "    while events[0] == -1:\n",
    "        del events[0]\n",
    "    return set(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sets_to_lists(my_list_of_e):\n",
    "#     my_list_of_events_2 = []\n",
    "#     for i,event in enumerate(my_list_of_e):    \n",
    "#         x = sorted(list(event))\n",
    "#         my_list_of_events_2.append(x)\n",
    "#     print(my_list_of_events_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-18 17:50:27 INFO: Writing properties to tmp file: corenlp_server-c890eba709854eb4.props\n",
      "2021-04-18 17:50:27 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-c890eba709854eb4.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-04-18 17:50:28 INFO: Writing properties to tmp file: corenlp_server-293735c4bdf54218.props\n",
      "2021-04-18 17:50:28 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-293735c4bdf54218.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-04-18 17:50:30 INFO: Writing properties to tmp file: corenlp_server-7e17be4cf6a540c1.props\n",
      "2021-04-18 17:50:30 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-7e17be4cf6a540c1.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-04-18 17:50:31 INFO: Writing properties to tmp file: corenlp_server-d8d052aa6abb4390.props\n",
      "2021-04-18 17:50:31 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-d8d052aa6abb4390.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-04-18 17:50:33 INFO: Writing properties to tmp file: corenlp_server-99392409406a4032.props\n",
      "2021-04-18 17:50:33 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-99392409406a4032.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-04-18 17:50:34 INFO: Writing properties to tmp file: corenlp_server-e20d176b8fec44d1.props\n",
      "2021-04-18 17:50:34 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-e20d176b8fec44d1.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-04-18 17:50:36 INFO: Writing properties to tmp file: corenlp_server-f3b7a8c1fd6b4932.props\n",
      "2021-04-18 17:50:36 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-f3b7a8c1fd6b4932.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-04-18 17:50:37 INFO: Writing properties to tmp file: corenlp_server-8a111f9ae2fc4ace.props\n",
      "2021-04-18 17:50:37 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-8a111f9ae2fc4ace.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-04-18 17:50:38 INFO: Writing properties to tmp file: corenlp_server-9547f7dedc224a30.props\n",
      "2021-04-18 17:50:38 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-9547f7dedc224a30.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-04-18 17:50:40 INFO: Writing properties to tmp file: corenlp_server-12ce1f5406c1492e.props\n",
      "2021-04-18 17:50:40 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-12ce1f5406c1492e.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-04-18 17:50:41 INFO: Writing properties to tmp file: corenlp_server-420f5a699e844b14.props\n",
      "2021-04-18 17:50:41 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-420f5a699e844b14.props -annotators tokenize,ssplit -preload -outputFormat serialized\n"
     ]
    }
   ],
   "source": [
    "my_list_of_events = []\n",
    "for i,name in enumerate(story_names):\n",
    "    text , annotated_story = open_and_annotate(name)\n",
    "    locations_dict, location_number_map, total_sentences = events_by_location_and_time(text, annotated_story)\n",
    "    my_list_of_events.append(construct_event_list(locations_dict, no_splitting[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0, 5, 6, 7, 9, 26, 29, 32, 45, 50, 61, 64, 65},\n",
       " {1, 7, 17, 22, 24, 48},\n",
       " {1, 8, 23, 60},\n",
       " {0, 1, 3, 11},\n",
       " {8, 17, 33},\n",
       " {32},\n",
       " {1, 16, 22, 37},\n",
       " {5, 18, 22},\n",
       " {0, 5, 25, 28, 32, 47, 49, 52, 56},\n",
       " {35, 37},\n",
       " {38}]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list_of_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0, 5, 6, 7, 9, 26, 29, 32, 45, 50, 61, 64, 65},\n",
       " {1, 7, 17, 22, 24, 48},\n",
       " {1, 8, 23, 60},\n",
       " {0, 1, 3, 11},\n",
       " {8, 17, 33},\n",
       " {32},\n",
       " {1, 16, 22, 37},\n",
       " {5, 18, 22},\n",
       " {0, 5, 25, 28, 32, 47, 49, 52, 56},\n",
       " {35, 37},\n",
       " {38}]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list_of_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sets_to_lists(my_list_of_e):\n",
    "    my_list_of_events_2 = []\n",
    "    for i,event in enumerate(my_list_of_e):    \n",
    "        x = sorted(list(event))\n",
    "        my_list_of_events_2.append(x)\n",
    "    print(my_list_of_events_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5, 6, 7, 9, 18, 26, 27, 29, 32, 45, 50, 57, 61, 64, 65], [1, 7, 17, 22, 24, 48], [0, 1, 3, 11], [8, 17, 33], [2, 32], [1, 16, 37], [18, 22], [6, 22, 28, 32, 47, 49, 52, 56], [35, 37], [38], [22, 31, 39, 43, 47, 51], [36, 41, 58, 63]]\n"
     ]
    }
   ],
   "source": [
    "sets_to_lists(my_list_of_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 5, 6, 7, 9, 26, 29, 32, 45, 50, 61, 64, 65], [1, 7, 17, 22, 24, 48], [1, 8, 23, 60], [0, 1, 3, 11], [8, 17, 33], [32], [1, 16, 22, 37], [5, 18, 22], [0, 5, 25, 28, 32, 47, 49, 52, 56], [35, 37], [38]]\n"
     ]
    }
   ],
   "source": [
    "sets_to_lists(my_list_of_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-18 17:08:31 INFO: Writing properties to tmp file: corenlp_server-034b5bda5077415a.props\n",
      "2021-04-18 17:08:31 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-034b5bda5077415a.props -annotators tokenize,ssplit -preload -outputFormat serialized\n"
     ]
    }
   ],
   "source": [
    "text , annotated_story = open_and_annotate('buddha_free_bird')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{21}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations_dict, location_number_map, total_sentences = events_by_location_and_time(text, annotated_story)\n",
    "construct_event_list(locations_dict, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[3,6,10,17,21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-30 14:17:36 INFO: Writing properties to tmp file: corenlp_server-e2c6defa91634ff1.props\n",
      "2021-03-30 14:17:36 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-e2c6defa91634ff1.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-03-30 14:17:41 INFO: Writing properties to tmp file: corenlp_server-e45431bd89bc41dc.props\n",
      "2021-03-30 14:17:41 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-e45431bd89bc41dc.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-03-30 14:17:44 INFO: Writing properties to tmp file: corenlp_server-65d12f71bd674582.props\n",
      "2021-03-30 14:17:44 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-65d12f71bd674582.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-03-30 14:17:48 INFO: Writing properties to tmp file: corenlp_server-3a702fb26c7c4e77.props\n",
      "2021-03-30 14:17:48 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-3a702fb26c7c4e77.props -annotators tokenize,ssplit -preload -outputFormat serialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For time_size =  300\n",
      "[[5, 6, 7, 9, 18, 26, 29, 32, 45, 50, 61, 64, 65], [1, 7, 17, 22, 24, 48], [8, 23, 60], [0, 1, 3, 11]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-30 14:17:57 INFO: Writing properties to tmp file: corenlp_server-43f3644be4f647e0.props\n",
      "2021-03-30 14:17:57 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-43f3644be4f647e0.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-03-30 14:18:01 INFO: Writing properties to tmp file: corenlp_server-5d598c6ad96a47d6.props\n",
      "2021-03-30 14:18:01 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-5d598c6ad96a47d6.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-03-30 14:18:05 INFO: Writing properties to tmp file: corenlp_server-3cc0e06c006949b8.props\n",
      "2021-03-30 14:18:05 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-3cc0e06c006949b8.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-03-30 14:18:09 INFO: Writing properties to tmp file: corenlp_server-83a1d708d0ce41fb.props\n",
      "2021-03-30 14:18:09 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-83a1d708d0ce41fb.props -annotators tokenize,ssplit -preload -outputFormat serialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For time_size =  400\n",
      "[[5, 6, 7, 9, 18, 26, 27, 29, 32, 45, 50, 57, 61, 64, 65], [1, 7, 17, 22, 24, 48], [8, 23, 60], [0, 1, 3, 11]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-30 14:18:18 INFO: Writing properties to tmp file: corenlp_server-be0187e9e3ed459f.props\n",
      "2021-03-30 14:18:18 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-be0187e9e3ed459f.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-03-30 14:18:22 INFO: Writing properties to tmp file: corenlp_server-da08a1cd72e34fc4.props\n",
      "2021-03-30 14:18:22 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-da08a1cd72e34fc4.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-03-30 14:18:26 INFO: Writing properties to tmp file: corenlp_server-609cfc3d09fc46e3.props\n",
      "2021-03-30 14:18:26 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-609cfc3d09fc46e3.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-03-30 14:18:30 INFO: Writing properties to tmp file: corenlp_server-0a3c390b878249fa.props\n",
      "2021-03-30 14:18:30 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-0a3c390b878249fa.props -annotators tokenize,ssplit -preload -outputFormat serialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For time_size =  500\n",
      "[[5, 6, 7, 9, 18, 26, 27, 29, 32, 45, 50, 57, 61, 64, 65], [1, 7, 17, 22, 24, 48], [8, 23, 60], [0, 1, 3, 11]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-30 14:18:37 INFO: Writing properties to tmp file: corenlp_server-0128adce0c624f64.props\n",
      "2021-03-30 14:18:37 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-0128adce0c624f64.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-03-30 14:18:41 INFO: Writing properties to tmp file: corenlp_server-134d8ad949e6451c.props\n",
      "2021-03-30 14:18:41 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-134d8ad949e6451c.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-03-30 14:18:45 INFO: Writing properties to tmp file: corenlp_server-f488b378392a4cdc.props\n",
      "2021-03-30 14:18:45 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-f488b378392a4cdc.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-03-30 14:18:49 INFO: Writing properties to tmp file: corenlp_server-a372ccfeeea04562.props\n",
      "2021-03-30 14:18:49 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-a372ccfeeea04562.props -annotators tokenize,ssplit -preload -outputFormat serialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For time_size =  600\n",
      "[[5, 6, 7, 9, 18, 26, 27, 29, 32, 45, 50, 57, 61, 64, 65], [1, 7, 17, 22, 24, 48], [8, 23, 60], [0, 1, 3, 11]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-30 14:18:58 INFO: Writing properties to tmp file: corenlp_server-5cb812e7d59c4942.props\n",
      "2021-03-30 14:18:58 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-5cb812e7d59c4942.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-03-30 14:19:03 INFO: Writing properties to tmp file: corenlp_server-10d0a21f11c044cf.props\n",
      "2021-03-30 14:19:03 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-10d0a21f11c044cf.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-03-30 14:19:07 INFO: Writing properties to tmp file: corenlp_server-da9c3d04554b4365.props\n",
      "2021-03-30 14:19:07 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-da9c3d04554b4365.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-03-30 14:19:11 INFO: Writing properties to tmp file: corenlp_server-cb27227f243143d1.props\n",
      "2021-03-30 14:19:11 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-cb27227f243143d1.props -annotators tokenize,ssplit -preload -outputFormat serialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For time_size =  700\n",
      "[[5, 6, 7, 9, 18, 26, 27, 29, 32, 45, 50, 57, 61, 64, 65], [1, 7, 17, 21, 22, 24, 27, 48], [8, 23, 60], [0, 1, 3, 11]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-30 14:19:18 INFO: Writing properties to tmp file: corenlp_server-dac016fa045143f0.props\n",
      "2021-03-30 14:19:18 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-dac016fa045143f0.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-03-30 14:19:23 INFO: Writing properties to tmp file: corenlp_server-c7402bc7e30944e9.props\n",
      "2021-03-30 14:19:23 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-c7402bc7e30944e9.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-03-30 14:19:27 INFO: Writing properties to tmp file: corenlp_server-fca25b9949394364.props\n",
      "2021-03-30 14:19:27 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-fca25b9949394364.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-03-30 14:19:31 INFO: Writing properties to tmp file: corenlp_server-562bef345c0e4cff.props\n",
      "2021-03-30 14:19:31 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-562bef345c0e4cff.props -annotators tokenize,ssplit -preload -outputFormat serialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For time_size =  800\n",
      "[[0, 5, 6, 7, 9, 18, 26, 27, 29, 32, 40, 45, 50, 57, 61, 64, 65], [1, 7, 17, 21, 22, 24, 27, 48], [0, 1, 8, 23, 32, 60], [0, 1, 3, 11]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-30 14:19:38 INFO: Writing properties to tmp file: corenlp_server-374948bda6934f6a.props\n",
      "2021-03-30 14:19:38 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-374948bda6934f6a.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-03-30 14:19:42 INFO: Writing properties to tmp file: corenlp_server-f555caa1506b41a6.props\n",
      "2021-03-30 14:19:42 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-f555caa1506b41a6.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-03-30 14:19:46 INFO: Writing properties to tmp file: corenlp_server-99b7a62703ba4a8c.props\n",
      "2021-03-30 14:19:46 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-99b7a62703ba4a8c.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-03-30 14:19:51 INFO: Writing properties to tmp file: corenlp_server-7495a3f1d81f43c4.props\n",
      "2021-03-30 14:19:51 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-7495a3f1d81f43c4.props -annotators tokenize,ssplit -preload -outputFormat serialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For time_size =  900\n",
      "[[0, 5, 6, 7, 9, 18, 26, 27, 29, 32, 40, 45, 50, 57, 61, 64, 65], [1, 7, 17, 21, 22, 24, 27, 48], [0, 1, 8, 23, 32, 60], [0, 1, 3, 11]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-30 14:19:59 INFO: Writing properties to tmp file: corenlp_server-221d8f3b67154c75.props\n",
      "2021-03-30 14:19:59 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-221d8f3b67154c75.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-03-30 14:20:03 INFO: Writing properties to tmp file: corenlp_server-21085e92e3534528.props\n",
      "2021-03-30 14:20:03 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-21085e92e3534528.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-03-30 14:20:07 INFO: Writing properties to tmp file: corenlp_server-f36715921ee84b18.props\n",
      "2021-03-30 14:20:07 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-f36715921ee84b18.props -annotators tokenize,ssplit -preload -outputFormat serialized\n",
      "2021-03-30 14:20:12 INFO: Writing properties to tmp file: corenlp_server-3f54b941857d4f4c.props\n",
      "2021-03-30 14:20:12 INFO: Starting server with command: java -Xmx5G -cp C:\\Users\\Giri\\stanza_corenlp\\* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 36000000 -threads 5 -maxCharLength 500000 -quiet True -serverProperties corenlp_server-3f54b941857d4f4c.props -annotators tokenize,ssplit -preload -outputFormat serialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For time_size =  1000\n",
      "[[0, 5, 6, 7, 9, 18, 26, 27, 29, 32, 40, 45, 50, 57, 61, 64, 65], [1, 7, 17, 21, 22, 24, 27, 48], [0, 1, 8, 23, 32, 60], [0, 1, 3, 11]]\n"
     ]
    }
   ],
   "source": [
    "for time_size in range(300,1100,100):\n",
    "    create_lexicons(30,14,300,time_size)\n",
    "    my_list_of_events = []\n",
    "    for i,name in enumerate(story_names):\n",
    "        text , annotated_story = open_and_annotate(name)\n",
    "        locations_dict, location_number_map, total_sentences = events_by_location_and_time(text, annotated_story)\n",
    "        my_list_of_events.append(construct_event_list(locations_dict, no_splitting[i]))\n",
    "    print(\"For time_size = \", time_size)\n",
    "    sets_to_lists(my_list_of_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = []\n",
    "for sn in range(len(story_names)):\n",
    "    text , annotated_story, sen_char_map = open_and_annotate(story_names[sn])\n",
    "    no_splitting_here = []\n",
    "    flag=0\n",
    "    for i, sentence in enumerate(annotated_story.sentence):\n",
    "        sentence = text[sentence.characterOffsetBegin:sentence.characterOffsetEnd].strip(\"\\n\").replace(\", \",\" \").replace(\".\",\"\").replace(\"-\",\" \").replace(\"?\",\"\").replace(\"!\",\"\").replace(\":\",\" \").replace(\"\\n\\n\",\"\").replace(\"\\n \\n\", '')\n",
    "        no_of_quotes = sentence.count('\"')\n",
    "        if no_of_quotes%2 != 0:        \n",
    "            flag = (flag + 1)%2\n",
    "        if flag != 0 or (no_of_quotes!=0):\n",
    "            no_splitting_here.append(i)\n",
    "    print(story_names[sn])\n",
    "    events.append(HAC(text, annotated_story, sen_char_map, no_splitting_here))\n",
    "    print(\"\\n\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
